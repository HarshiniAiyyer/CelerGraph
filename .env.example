# Backend — API & services

# Groq LLM
GROQ_API_KEY=your_groq_api_key
LLM_MODEL_NAME=openai/gpt-oss-120b
LLM_TEMPERATURE=0.2
LLM_MAX_TOKENS=800

# Embeddings
EMBEDDING_MODEL=BAAI/bge-small-en
EMBEDDING_CACHE_SIZE=1
EMBEDDING_NORMALIZE=true

# ChromaDB (vector store)
CHROMA_PATH=vectorstore/chroma_db
CHROMA_NODE_COLLECTION=node_embeddings
CHROMA_CODE_COLLECTION=code_chunks
CHROMA_CACHE_COLLECTION=semantic_cache
CHROMA_SIMILARITY_SPACE=cosine

# Semantic cache
CACHE_THRESHOLD=0.9

# Neo4j (optional)
USE_NEO4J=false
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=password


# Frontend — Vite
# Place these in frontend/.env (for dev) or frontend/.env.production (for build)
VITE_API_BASE_URL=/api

# Rate limiting (per IP)
RATE_LIMIT_CHAT_LIMIT=5
RATE_LIMIT_CHAT_WINDOW=10.0
RATE_LIMIT_STREAM_LIMIT=5
RATE_LIMIT_STREAM_WINDOW=10.0
RATE_LIMIT_INDEX_LIMIT=2
RATE_LIMIT_INDEX_WINDOW=60.0
RATE_LIMIT_CACHE_CLEAR_LIMIT=2
RATE_LIMIT_CACHE_CLEAR_WINDOW=60.0
RATE_LIMIT_HEALTH_LIMIT=10
RATE_LIMIT_HEALTH_WINDOW=5.0
